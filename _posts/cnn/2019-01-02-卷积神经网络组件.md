---
layout:     post
title:      卷积神经网络组件
subtitle:   
date:       2019-01-02
author:     BY Lacoboi
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - CNN
---


# 卷积神经网络组件

目前，卷积神经网络（CNN）中常见的组件有输入层、卷积层、激活层、池化层、全连接层等，下面将对这些常见的层的作用和原理进行简要介绍总结。

## 输入层

输入层（Input layer）将原始数据进行预处理后，送到卷积神经网络中，输入数据没有明确定义，可以是数组图像，也可以是音频经过傅里叶变换后的二维波形数据，也可以是自然语言处理中一维表示的句子向量。

## 卷积层

卷积层（Convolution layer）是卷积神经网络的核心组件，它的作用是对输入数据进行特征提取。

对于输入大小为 $K$ 通道 ，输出大小为 $L$ 通道，需要 $K \times L$ 个卷积核实现通道数目转换，假设卷积核大小是 $I \times J$，输出特征图大小是 $M \times N$，则每个样本进行一次前向时卷积层的计算量（Calculations, 乘累加次数）为 $MAC = I \times J \times M \times N \times K \times L$，而卷积和学习到的参数为（Params）为 $I \times J \times K \times L$，所以计算量与参数量的比值 $CPR = Calculations \div Params = M \times N$，从这里可以看出，卷积输出的特征图越大，CPR越高，也就是参数的利用率越高。

卷积的优点：

- 权值共享
- 局部连接

常见的卷积层的类型有：

- 标准卷积
- 带孔卷积（能够增大感受野）
- 转置卷积（能够增大特征图，起到反卷积的作用）
- 深度可分离卷积（降低计算量）

## 激活层

激活层（Activation Layer）负责对卷积层抽取的特征进行激活，卷积操作本质上是将输入图像和卷积核进行相应的线性变化，所以需要引入激活层（非线性层）对其进行非线性映射。

常见的激活层有 $sigmoid$、$tanh$、$relu$，其中最常用的是$relu$函数，又叫线性整流器。

## 池化层

池化层（Pooling layer）就是对特征进行下采样，其作用是对感受野内的特征进行筛选，提取区域内最具有代表性的特征；能够有效降低输出特征尺度，进而减少模型所需要的计算量。池化层能起作用的真正原因是非线性映射能力和保持一定量平移不变性的能力。

根据操作类型，可以分为最标准池化层（包括大池化（Max pooling）、平均池化（Average pooling））、重叠池化（操作与标准池化相同，不同点在于滑动的步长小与池化层的尺寸$k$，最后得到的特征表达能力更强）、特征金字塔池化（ROI Pooling）。

池化层的优点有：

- 具有平移不变性和旋转不变性
- 减少特征大小，减小模型计算量和参数
- 获得定长输入（如Roi pooling）

缺点：

- 在语义分割任务中，多次下采样会导致图像中的某些目标细节丢失，结果不精细

## 全连接层

全连接层(Full Connected Layer)就是一个线性特征映射的过程，将多维的特征输入映射为二维的特征输出。
