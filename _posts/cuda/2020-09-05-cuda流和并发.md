---
layout:     post
title:      cuda流和并发
subtitle:   
date:       2020-09-05
author:     BY Lacoboi
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - CUDA
---

# 6.流和并发


## 6.1 流和事件概述

### 6.1.1 CUDA流

### 6.1.2 流的调度
#### 6.1.2.1 虚假的依赖关系
#### 6.1.2.2 Hyper-Q技术


### 6.1.3 流的优先级


### 6.1.4 CUDA事件
#### 6.1.4.1 创建和销毁
#### 6.1.4.2 记录事件和计算运行时间


### 6.1.5 流同步
#### 6.1.5.1 阻塞流和非阻塞流
#### 6.1.5.2 隐式同步
#### 6.1.5.3 显式同步
#### 6.1.5.4 可配置事件


## 6.2 并发内核执行
前面说到了流、事件和同步的概念，接下来的几个例子，介绍并发内核的几个基本问题，包括不限于以下几个方面：
- 使用深度优先或者广度优先方法的调度工作
- 调整硬件工作队列
- 在Kepler设备和Fermi设备上避免虚假的依赖关系
- 检查默认流的阻塞行为
- 在非默认流之间添加依赖关系
- 检查资源使用是如何影响并发的

### 6.2.1 非空流中的并发内核
创建不同的非空流，每个非空流中插入4个核函数，观察核函数的执行。
```c
#include <cuda_runtime.h>
#include <stdio.h>
#include "freshman.h"

#define N 300000
__global__ void kernel_1()
{
    double sum=0.0;
    for(int i=0;i<N;i++)
        sum=sum+tan(0.1)*tan(0.1);
}
__global__ void kernel_2()
{
    double sum=0.0;
    for(int i=0;i<N;i++)
        sum=sum+tan(0.1)*tan(0.1);
}
__global__ void kernel_3()
{
    double sum=0.0;
    for(int i=0;i<N;i++)
        sum=sum+tan(0.1)*tan(0.1);
}
__global__ void kernel_4()
{
    double sum=0.0;
    for(int i=0;i<N;i++)
        sum=sum+tan(0.1)*tan(0.1);
}
int main()
{
    setenv("CUDA_DEVICE_MAX_CONNECTIONS","32",1);
    int dev = 0;
    cudaSetDevice(dev);
    int n_stream=16;
    cudaStream_t *stream=(cudaStream_t*)malloc(n_stream*sizeof(cudaStream_t));
    for(int i=0;i<n_stream;i++)
    {
        cudaStreamCreate(&stream[i]);
    }
    dim3 block(1);
    dim3 grid(1);
    cudaEvent_t start,stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    cudaEventRecord(start,0);
    for(int i=0;i<n_stream;i++)
    {
        kernel_1<<<grid,block,0,stream[i]>>>();
        kernel_2<<<grid,block,0,stream[i]>>>();
        kernel_3<<<grid,block,0,stream[i]>>>();
        kernel_4<<<grid,block,0,stream[i]>>>();
    }
    cudaEventRecord(stop,0);
    CHECK(cudaEventSynchronize(stop));
    float elapsed_time;
    cudaEventElapsedTime(&elapsed_time,start,stop);
    printf("elapsed time:%f ms\n",elapsed_time);

    for(int i=0;i<n_stream;i++)
    {
        cudaStreamDestroy(stream[i]);
    }
    cudaEventDestroy(start);
    cudaEventDestroy(stop);
    free(stream);
    CHECK(cudaDeviceReset());
    return 0;
}
```

### 6.2.2 Fermi GPU 上的虚假依赖关系
`Fermi GPU` 只有一个硬件工作队列，使用广度优先的方法组织任务，可以解决虚假依赖的问题。
```c
// dispatch job with breadth first way
for (int i = 0; i < n_streams; i++)
    kernel_1<<<grid, block, 0, streams[i]>>>();
for (int i = 0; i < n_streams; i++)
    kernel_2<<<grid, block, 0, streams[i]>>>();
for (int i = 0; i < n_streams; i++)
    kernel_3<<<grid, block, 0, streams[i]>>>();
for (int i = 0; i < n_streams; i++)
    kernel_4<<<grid, block, 0, streams[i]>>>();
```

### 6.2.3 使用OpenMP的调度操作
`OpenMP` 是一种非常好的并行工具：
```c
omp_set_num_thread(n_stream); // 创建 n_stream 个线程
#pragma omp parallel // 宏指令表示大括号中的代码是每个线程需要执行的代码
    {
        int i=omp_get_thread_num();
        kernel_1<<<grid,block,0,stream[i]>>>();
        kernel_2<<<grid,block,0,stream[i]>>>();
        kernel_3<<<grid,block,0,stream[i]>>>();
        kernel_4<<<grid,block,0,stream[i]>>>();
    }
```

