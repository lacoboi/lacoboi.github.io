---
layout:     post
title:      5.共享内存和常量内存
subtitle:   
date:       2019-08-10
author:     BY Lacoboi
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - CUDA
---

# 5.共享内存和常量内存

学习如何使用共享内存，提升核函数性能。

## 5.1 CUDA共享内存概述

GPU内存按照类型（物理上的位置）可以分为：
- 板载内存（容量高、延迟高、带宽低）
- 片上内存（容量小、延时低、带宽高）

共享内存是片上内存，与L1 cache共享片上的64KB的存储，共享内存可以看作是一种可编程、可控制的缓存，其主要作用有：
- 块内线程通信的通道
- 用于全局内存数据的缓存
- 用于转换数据、优化全局内存的访问模型


### 5.1.1 共享内存

共享内存（shared memory, SMEM）是 `GPU` 的关键部分，在物理层面，每个 `SM` 都有一个小的片上内存池，这个内存池被 `SM` 上活跃线程块上的所有线程共享。共享内存可以使同一线程块中可以相互协同，降低全局内存读取的延迟。

在GPU中，一级缓存、二级缓存以及共享内存、常量内存的关系如下图所示：

   ![GPU中的内存](/img/post_images/cuda/5-1.png)

在 `SM` 上有一级缓存、二级缓存、只读缓存以及常量缓存，所有从 `DRAM` 全局内存中过来的数据都要经过二级缓存，相比全局内存和二级缓存，SM上的内存延迟更低、带宽更高。

共享内存在所属的线程块被执行的时候建立，线程块执行完成后共享内存释放，线程块和它的共享内存有着相同的生命周期。

每个线程对于共享内存的访问请求，有三种情况：
1. 最好的情况是当前线程束中的每个线程都访问一个不冲突的共享内存地址，这种情况下一个事务就可以完成访问，效率最高。
2. 当访问有冲突的时候，最差情况是一个线程束需要32个内存事务。
3. 如果一个线程束中的32个线程访问同一个地址，那么一个线程访问完成以后会以广播的形式告诉其他线程。


### 5.1.2 共享内存分配

共享内存的定义包含两种：
- 全局共享内存（在所有的核函数外面定义，所有的核函数共享）
- 本地共享内存（在函数中定义，只能被当前的核函数访问）

共享内存的分配包括两种：
- 动态分配（在定义的时候不指定内存大小，调用核函数的时候指定，只能是一维的，定义时需要extern关键字）
- 静态分配（在定义的时候就指定内存大小，可以是一维、二维或者三维的）

共享内存的声明通过关键字 `__shared__` 指定，如：
```c
__shared__ float a[size_x][size_y];  // 声明一个静态共享内存
extern __shared__ int tile[]; // 声明一个动态共享内存
```

对于动态共享内存，在核函数调用的时候，需要在<<< >>>中将共享内存大小以第三个参数传入。

### 5.1.3 共享内存存储体和访问模式

优化内存性能主要有两个关键：
- 延迟
- 带宽

共享内存是用来隐藏全局内存延迟以及提高带宽性能的主要武器。

#### 5.1.3.1 内存存储体

共享内存是一个**一维的地址空间**，二维三维或者更多维的地址都要转换为一维的来应对物理上的内存地址。为了提高内存带宽，共享内存被分为32个同样大小的内存模型，成为存储体（bank），它们可以被同时访问。32个存储体对应的是一个线程束中有32个线程，如果一个线程束中的线程在访问共享内存的时候，都访问不同的存储体（无冲突），那么一个事务就能够完成，如果有冲突，则需要多个内存事务，这样就会导致带宽利用率降低。

#### 5.1.3.2 存储体冲突

多个线程访问一个存储体的时候会导致冲突（需要注意的是访问的是同一存储体中的不同地址，如果是同一个地址，则会通过广播形式，不会导致冲突）。线程束访问共享内存的时候有三种经典形式：
- 并行访问，多个地址访问多存储体
- 串行访问，多个地址访问同一存储体
- 广播访问，单一地址读取单一存储体

并行访问是最常见、效率最高的，可以分为完全无冲突和小部分冲突，完全无冲突是理想模式，这种情况下，线程束中所有线程对内存的访问通过一个事务完成，效率最高，小部分冲突时，不冲突的部分可以通过一个内存事务完成，冲突的部分被分割为由另外的不冲突的事务执行，会降低效率。

当小部分冲突编程完全冲突就是串行模式，这是最糟糕的形式，即所有的线程访问同一个存储体。

广播访问是所有的线程访问一个地址，这个时候，一个内存事务执行完毕后，一个线程得到了这个地址的数据，会通过广播的形式告诉其他所有的线程，虽然延迟相比与完全的并行访问并不慢，但是只读取了一个数据，会导致带宽利用率很差。




### 5.1.4 配置共享内存

### 5.1.5 同步



## 5.2 共享内存的数据布局



## 5.3 减少全局内存访问


## 5.4 合并的全局内存访问



## 5.5 常量内存



## 5.6 线程束洗牌指令