---
layout:     post
title:      CV中注意力机制（1）
subtitle:   
date:       2020-02-11
author:     BY Lacoboi
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - CV
    - attention
---

## SE模块

`SENet` 是 `Squeeze-and-Excitation Networks` 的缩写，`SE` 模块思想简单，主要学习到了 `channel` 之间的相关性，筛选出了针对通道的注意力，只增加了少量的计算量，对于分类任务，大的网络上能有0.5%到1.5%的提升，轻量级的网络有1.5%到2.0%的提升。

通过下图可以理解 `SENet` 的实现过程，对卷积得到的特征图进行处理，得到一个 `1x1xC` 的向量作为每个通道的评价分数，然后将该分数施加到对应的通道上，

   ![SENet](/img/post_images/attention/senet.webp)

`SE` 模块主要有三个子模块:

- **Sequeeze**， 对 `C x H x W` 的特征图进行 global average pooling，得到大小为 `1 x 1 x C` 的具有全局感受野的特征图。

- **Excitation**，使用一个全连接网络，对 `Squeeze` 之后的特征图做非线性变换。

- **特征重标定**，使用 `Excitation` 得到的结果作为权重，乘到输入特征上。

   ![SENet2](/img/post_images/attention/senet2.webp)

下面的代码基于 `pytorch` 的 `SENet` 的简单实现：

```python
class SELayer(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)
```

## SKNet

`SKNet（Selective-Kernel-Networks）` 是 `SENet` 的加强版，其核心思想是使用多尺度的特征得到特征权重，得到特征的加权系数，下图是 `SKNet` 的原理图，

   ![SKNet](/img/post_images/attention/sknet.jpeg)

对于原始的特征图 `X`，分别利用 `kernel` 大小为 `3x3`、`5x5` 和 `7x7` 的卷积层进行卷积，得到 `U1`、`U2` 和 `U3`，然后将三个特征图进行叠加得到`U`,特征图`U`融合了不同感受野的信息，对于`U`沿着H和W维度求平均值，得到`1x1xC`的一维向量，表示各个通道的重要程度，之后的步骤与`SENet`，对一维向量进行非线性变换，得到三个通道注意力向量，分别与对应的特征图进行相乘，再融合即可得到输出的特征`A`,

基于pytorch的实现如下：

```python
import torch.nn as nn
import torch

class SKConv(nn.Module):
    def __init__(self, features, WH, M, G, r, stride=1, L=32):
        super(SKConv, self).__init__()
        d = max(int(features / r), L)
        self.M = M
        self.features = features
        self.convs = nn.ModuleList([])
        for i in range(M):
            # 使用不同kernel size的卷积
            self.convs.append(
                nn.Sequential(
                    nn.Conv2d(features,
                              features,
                              kernel_size=3 + i * 2,
                              stride=stride,
                              padding=1 + i,
                              groups=G), nn.BatchNorm2d(features),
                    nn.ReLU(inplace=False)))

        self.fc = nn.Linear(features, d)
        self.fcs = nn.ModuleList([])
        for i in range(M):
            self.fcs.append(nn.Linear(d, features))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        for i, conv in enumerate(self.convs):
            fea = conv(x).unsqueeze_(dim=1)
            if i == 0:
                feas = fea
            else:
                feas = torch.cat([feas, fea], dim=1)
        fea_U = torch.sum(feas, dim=1)
        fea_s = fea_U.mean(-1).mean(-1)
        fea_z = self.fc(fea_s)
        for i, fc in enumerate(self.fcs):
            print(i, fea_z.shape)
            vector = fc(fea_z).unsqueeze_(dim=1)
            print(i, vector.shape)
            if i == 0:
                attention_vectors = vector
            else:
                attention_vectors = torch.cat([attention_vectors, vector],
                                              dim=1)
        attention_vectors = self.softmax(attention_vectors)
        attention_vectors = attention_vectors.unsqueeze(-1).unsqueeze(-1)
        fea_v = (feas * attention_vectors).sum(dim=1)
        return fea_v

if __name__ == "__main__":
    t = torch.ones((32, 256, 24,24))
    sk = SKConv(256,WH=1,M=2,G=1,r=2)
    out = sk(t)
    print(out.shape)
```
